# Model-compression（剪枝、量化、蒸馏）

需要做模型压缩的原因在于我们有将模型部署在资源受限的设备上的需求，比如很多移动设备，在这些设备上有受限的存储空间和受限的计算能力。

1、剪枝

深度学习网络模型从卷积层到全连接层存在着大量冗余的参数，大量神经元激活值趋近于0，将这些神经元去除后可以表现出同样的模型表达能力，这种情况被称为过参数化，而对应的技术则被称为模型剪枝。
网络剪枝的过程主要分以下几步：
①训练网络；
②评估权重和神经元的重要性：可以用L1、L2来评估权重的重要性，用不是0的次数来衡量神经元的重要性；
③对权重或者神经元的重要性进行排序然后移除不重要的权重或神经元；
④移除部分权重或者神经元后网络的准确率会受到一些损伤，因此我们要进行微调，也就是使用原来的训练数据更新一下参数，往往就可以复原回来；
⑤为了不会使剪枝造成模型效果的过大损伤，我们每次都不会一次性剪掉太多的权重或神经元，因此这个过程需要迭代，也就是说剪枝且微调一次后如果剪枝后的模型大小还不令人满意就回到步骤后迭代上述过程直到满意为止。

1.1 结构化剪枝

结构化剪枝算法的对象不是单个参数，它可以是一个向量、一个内核，也可以是一个滤波器。滤波器有时指一个卷积核，在一些网络框架中也可以指多个卷积核。滤波器剪枝算法即通过计算直接删除一个或多个卷积核。一
次剪掉整个结构化信息是由于网络不同，有的卷积核计算得到的特征图矩阵趋于零矩阵，或存在两个特征图矩阵的数值近似相等，这种情况下删除特征值小和冗余矩阵对整体结果影响不大，但可以很大程度上减少计算量。



1.2 非结构化剪枝

1.3 自动化剪枝
